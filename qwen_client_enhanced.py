# -*- coding: utf-8 -*-
"""
å¢å¼ºç‰ˆé€šä¹‰åƒé—®å®¢æˆ·ç«¯ - æ”¯æŒFunction Callingå’Œæµå¼å“åº”
å‚è€ƒHydroSISäº‘æœåŠ¡æ¶æ„æ–¹æ¡ˆä¸­çš„ChatServiceè®¾è®¡
"""

import json
import logging
from typing import Dict, List, Optional, AsyncGenerator, Callable
import dashscope
from dashscope import Generation
from http import HTTPStatus

logger = logging.getLogger(__name__)


class QwenChatService:
    """
    å¢å¼ºç‰ˆé€šä¹‰åƒé—®å¯¹è¯æœåŠ¡
    æ”¯æŒï¼š
    1. Function Calling (å·¥å…·è°ƒç”¨)
    2. æµå¼å“åº”
    3. MCPå·¥å…·é›†æˆ
    4. å¯¹è¯å†å²ç®¡ç†
    """
    
    def __init__(self, api_key: str, model: str = "qwen-plus", mcp_manager=None):
        """
        åˆå§‹åŒ–å¯¹è¯æœåŠ¡
        
        Args:
            api_key: é˜¿é‡Œäº‘APIå¯†é’¥
            model: æ¨¡å‹åç§° (qwen-turbo/qwen-plus/qwen-max)
            mcp_manager: MCPæœåŠ¡ç®¡ç†å™¨å®ä¾‹
        """
        if not api_key or api_key == "your-api-key":
            raise ValueError("è¯·é…ç½®æœ‰æ•ˆçš„é˜¿é‡Œäº‘APIå¯†é’¥")
        
        dashscope.api_key = api_key
        self.model = model
        self.mcp_manager = mcp_manager
        
        # å¯¹è¯å†å²å­˜å‚¨ {conversation_id: messages}
        self.conversations: Dict[str, List[Dict]] = {}
        
        logger.info(f"âœ… é€šä¹‰åƒé—®å¯¹è¯æœåŠ¡åˆå§‹åŒ–æˆåŠŸ - æ¨¡å‹: {model}")
    
    def _build_system_prompt(self) -> str:
        """æ„å»ºç³»ç»Ÿæç¤ºè¯"""
        return """ä½ æ˜¯HydroNetæ°´ç½‘æ™ºèƒ½åŠ©æ‰‹ï¼Œä¸“é—¨å¸®åŠ©ç”¨æˆ·è¿›è¡Œæ°´ç½‘åˆ†æå’Œç®¡ç†ã€‚

ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä¸“ä¸šå·¥å…·ï¼š
- simulation: æ°´ç½‘ä»¿çœŸæ¨¡æ‹Ÿï¼ˆé¢„æµ‹æµé‡ã€æ°´ä½ã€å‹åŠ›ç­‰ï¼‰
- identification: ç³»ç»Ÿè¾¨è¯†ï¼ˆè¯†åˆ«ç®¡ç½‘å‚æ•°ã€æ ¡å‡†æ¨¡å‹ï¼‰
- scheduling: ä¼˜åŒ–è°ƒåº¦ï¼ˆç”Ÿæˆæœ€ä¼˜è°ƒåº¦æ–¹æ¡ˆï¼Œé™ä½èƒ½è€—ï¼‰
- control: æ§åˆ¶ç­–ç•¥ï¼ˆè®¾è®¡PIDã€MPCç­‰æ§åˆ¶å™¨ï¼‰
- testing: æ€§èƒ½æµ‹è¯•ï¼ˆè¯„ä¼°ç³»ç»Ÿå¯é æ€§å’Œæ•ˆç‡ï¼‰

**é‡è¦æŒ‡å¯¼åŸåˆ™**ï¼š
1. å½“ç”¨æˆ·è¯¢é—®å…·ä½“çš„è®¡ç®—ã€åˆ†æä»»åŠ¡æ—¶ï¼Œä¸»åŠ¨è°ƒç”¨ç›¸åº”å·¥å…·
2. è§£é‡Šæ¸…æ¥šæ¯ä¸ªå·¥å…·çš„ç”¨é€”å’Œæ‰€éœ€å‚æ•°
3. å¯¹å·¥å…·è¿”å›çš„ç»“æœè¿›è¡Œä¸“ä¸šè§£è¯»
4. ç”¨ç®€æ´ã€ä¸“ä¸šã€å‹å¥½çš„ä¸­æ–‡å›ç­”

**ç¤ºä¾‹åœºæ™¯**ï¼š
- ç”¨æˆ·è¯´"å¸®æˆ‘æ¨¡æ‹Ÿä¸€ä¸‹æ°´ç½‘è¿è¡Œ"â†’ è°ƒç”¨simulationå·¥å…·
- ç”¨æˆ·è¯´"ä¼˜åŒ–è°ƒåº¦æ–¹æ¡ˆ"â†’ è°ƒç”¨schedulingå·¥å…·
- ç”¨æˆ·è¯´"è®¾è®¡ä¸€ä¸ªPIDæ§åˆ¶å™¨"â†’ è°ƒç”¨controlå·¥å…·"""
    
    def _get_mcp_tools(self) -> List[Dict]:
        """è·å–MCPå·¥å…·åˆ—è¡¨ï¼ˆè½¬æ¢ä¸ºé€šä¹‰åƒé—®æ ¼å¼ï¼‰"""
        if not self.mcp_manager:
            return []
        
        mcp_services = self.mcp_manager.get_tools_list()
        
        # è½¬æ¢ä¸ºé€šä¹‰åƒé—®Functionæ ¼å¼
        tools = []
        for service in mcp_services:
            tool = {
                "type": "function",
                "function": {
                    "name": service['name'],
                    "description": service['description'],
                    "parameters": service.get('parameters', {
                        "type": "object",
                        "properties": {},
                        "required": []
                    })
                }
            }
            tools.append(tool)
        
        logger.info(f"ğŸ“¦ åŠ è½½äº† {len(tools)} ä¸ªMCPå·¥å…·")
        return tools
    
    async def chat_stream(
        self,
        user_id: str,
        conversation_id: str,
        message: str,
        on_chunk: Optional[Callable] = None
    ) -> AsyncGenerator[Dict, None]:
        """
        æµå¼å¯¹è¯ï¼ˆæ”¯æŒå·¥å…·è°ƒç”¨ï¼‰
        
        Args:
            user_id: ç”¨æˆ·ID
            conversation_id: å¯¹è¯ID
            message: ç”¨æˆ·æ¶ˆæ¯
            on_chunk: å›è°ƒå‡½æ•°ï¼ˆå¤„ç†æ¯ä¸ªchunkï¼‰
            
        Yields:
            æ¶ˆæ¯chunkå­—å…¸:
            - type: 'text' | 'tool_call' | 'tool_result' | 'complete'
            - content: å†…å®¹
            - tool_name: å·¥å…·åç§°ï¼ˆä»…tool_call/tool_resultï¼‰
            - status: running | completed | failed
        """
        try:
            # 1. åˆå§‹åŒ–å¯¹è¯å†å²
            if conversation_id not in self.conversations:
                self.conversations[conversation_id] = [
                    {"role": "system", "content": self._build_system_prompt()}
                ]
            
            # 2. æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
            self.conversations[conversation_id].append({
                "role": "user",
                "content": message
            })
            
            # 3. è·å–MCPå·¥å…·åˆ—è¡¨
            tools = self._get_mcp_tools()
            
            # 4. è°ƒç”¨é€šä¹‰åƒé—®ï¼ˆæµå¼ + Function Callingï¼‰
            logger.info(f"ğŸ’¬ ç”¨æˆ· {user_id} å‘é€æ¶ˆæ¯: {message[:50]}...")
            
            responses = Generation.call(
                model=self.model,
                messages=self.conversations[conversation_id],
                tools=tools if tools else None,
                result_format='message',
                stream=True,
                incremental_output=True
            )
            
            # 5. å¤„ç†å“åº”æµ
            assistant_content = ""
            tool_calls = []
            
            for response in responses:
                if response.status_code == HTTPStatus.OK:
                    choice = response.output.choices[0]
                    message_obj = choice.message
                    
                    # å¤„ç†å·¥å…·è°ƒç”¨
                    if hasattr(message_obj, 'tool_calls') and message_obj.tool_calls:
                        for tool_call in message_obj.tool_calls:
                            tool_name = tool_call.function.name
                            tool_args = json.loads(tool_call.function.arguments)
                            
                            logger.info(f"ğŸ”§ è°ƒç”¨å·¥å…·: {tool_name}")
                            
                            # é€šçŸ¥å‰ç«¯å·¥å…·è°ƒç”¨å¼€å§‹
                            chunk = {
                                'type': 'tool_call',
                                'tool_name': tool_name,
                                'status': 'running',
                                'arguments': tool_args
                            }
                            
                            if on_chunk:
                                on_chunk(chunk)
                            yield chunk
                            
                            # æ‰§è¡ŒMCPå·¥å…·
                            try:
                                result = await self.mcp_manager.call_tool(
                                    tool_name,
                                    tool_args,
                                    user_id=user_id
                                )
                                
                                logger.info(f"âœ… å·¥å…· {tool_name} æ‰§è¡ŒæˆåŠŸ")
                                
                                # é€šçŸ¥å‰ç«¯å·¥å…·æ‰§è¡Œå®Œæˆ
                                result_chunk = {
                                    'type': 'tool_result',
                                    'tool_name': tool_name,
                                    'status': 'completed',
                                    'result': result
                                }
                                
                                if on_chunk:
                                    on_chunk(result_chunk)
                                yield result_chunk
                                
                                # ä¿å­˜å·¥å…·è°ƒç”¨ç»“æœ
                                tool_calls.append({
                                    "tool_call_id": tool_call.id,
                                    "role": "tool",
                                    "name": tool_name,
                                    "content": json.dumps(result, ensure_ascii=False)
                                })
                                
                            except Exception as e:
                                logger.error(f"âŒ å·¥å…· {tool_name} æ‰§è¡Œå¤±è´¥: {e}")
                                error_chunk = {
                                    'type': 'tool_result',
                                    'tool_name': tool_name,
                                    'status': 'failed',
                                    'error': str(e)
                                }
                                if on_chunk:
                                    on_chunk(error_chunk)
                                yield error_chunk
                    
                    # å¤„ç†æ–‡æœ¬å†…å®¹ï¼ˆæµå¼è¾“å‡ºï¼‰
                    if hasattr(message_obj, 'content') and message_obj.content:
                        delta_content = message_obj.content
                        if delta_content:
                            assistant_content += delta_content
                            
                            text_chunk = {
                                'type': 'text',
                                'content': delta_content
                            }
                            
                            if on_chunk:
                                on_chunk(text_chunk)
                            yield text_chunk
                else:
                    logger.error(f"APIè°ƒç”¨å¤±è´¥: {response.code} - {response.message}")
                    raise Exception(f"APIè°ƒç”¨å¤±è´¥: {response.message}")
            
            # 6. å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œéœ€è¦å†æ¬¡è°ƒç”¨LLMç”Ÿæˆæœ€ç»ˆå›ç­”
            if tool_calls:
                logger.info(f"ğŸ”„ åŸºäºå·¥å…·ç»“æœç”Ÿæˆæœ€ç»ˆå›ç­”...")
                
                # å°†å·¥å…·è°ƒç”¨å’Œç»“æœæ·»åŠ åˆ°å†å²
                messages_with_tools = self.conversations[conversation_id].copy()
                messages_with_tools.append({
                    "role": "assistant",
                    "content": "",
                    "tool_calls": tool_calls
                })
                messages_with_tools.extend(tool_calls)
                
                # å†æ¬¡è°ƒç”¨LLM
                final_responses = Generation.call(
                    model=self.model,
                    messages=messages_with_tools,
                    result_format='message',
                    stream=True,
                    incremental_output=True
                )
                
                final_content = ""
                for response in final_responses:
                    if response.status_code == HTTPStatus.OK:
                        choice = response.output.choices[0]
                        if hasattr(choice.message, 'content') and choice.message.content:
                            delta = choice.message.content
                            final_content += delta
                            
                            text_chunk = {
                                'type': 'text',
                                'content': delta
                            }
                            
                            if on_chunk:
                                on_chunk(text_chunk)
                            yield text_chunk
                
                assistant_content = final_content
            
            # 7. ä¿å­˜åŠ©æ‰‹å›å¤åˆ°å†å²
            self.conversations[conversation_id].append({
                "role": "assistant",
                "content": assistant_content
            })
            
            # 8. é™åˆ¶å†å²é•¿åº¦
            self._trim_history(conversation_id, max_messages=30)
            
            # 9. å‘é€å®Œæˆä¿¡å·
            complete_chunk = {
                'type': 'complete',
                'conversation_id': conversation_id
            }
            if on_chunk:
                on_chunk(complete_chunk)
            yield complete_chunk
            
            logger.info(f"âœ… å¯¹è¯å®Œæˆ: {conversation_id}")
            
        except Exception as e:
            logger.error(f"âŒ å¯¹è¯å¤„ç†å¤±è´¥: {e}", exc_info=True)
            error_chunk = {
                'type': 'error',
                'error': str(e)
            }
            if on_chunk:
                on_chunk(error_chunk)
            yield error_chunk
    
    def _trim_history(self, conversation_id: str, max_messages: int = 30):
        """é™åˆ¶å¯¹è¯å†å²é•¿åº¦"""
        if conversation_id in self.conversations:
            messages = self.conversations[conversation_id]
            if len(messages) > max_messages:
                # ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯å’Œæœ€è¿‘çš„å¯¹è¯
                system_msgs = [m for m in messages if m.get("role") == "system"]
                recent_msgs = messages[-max_messages:]
                self.conversations[conversation_id] = system_msgs + recent_msgs
                logger.info(f"ğŸ“ å¯¹è¯å†å²å·²è£å‰ªè‡³ {max_messages} æ¡")
    
    def clear_conversation(self, conversation_id: str):
        """æ¸…é™¤å¯¹è¯å†å²"""
        if conversation_id in self.conversations:
            del self.conversations[conversation_id]
            logger.info(f"ğŸ—‘ï¸ å·²æ¸…é™¤å¯¹è¯å†å²: {conversation_id}")
    
    def get_conversation_history(self, conversation_id: str) -> List[Dict]:
        """è·å–å¯¹è¯å†å²"""
        return self.conversations.get(conversation_id, [])
    
    def is_available(self) -> bool:
        """æ£€æŸ¥æœåŠ¡æ˜¯å¦å¯ç”¨"""
        return bool(dashscope.api_key and dashscope.api_key != "your-api-key")


# å…¼å®¹æ—§ç‰ˆæœ¬çš„ç®€å•å®¢æˆ·ç«¯ç±»
class QwenClient:
    """ç®€å•ç‰ˆé€šä¹‰åƒé—®å®¢æˆ·ç«¯ï¼ˆå‘åå…¼å®¹ï¼‰"""
    
    def __init__(self, api_key: str, model: str = "qwen-turbo"):
        self.service = QwenChatService(api_key, model)
        self.model = model
        self.api_key = api_key
    
    def is_available(self) -> bool:
        return self.service.is_available()
    
    def chat(self, message: str, conversation_id: Optional[str] = None, 
             system_prompt: Optional[str] = None, **kwargs) -> Dict:
        """åŒæ­¥chatæ–¹æ³•ï¼ˆä¸ºäº†å…¼å®¹ï¼‰"""
        import asyncio
        import uuid
        
        if not conversation_id:
            conversation_id = str(uuid.uuid4())
        
        # ç®€å•å®ç°ï¼šæ”¶é›†æ‰€æœ‰æµå¼å“åº”
        content = ""
        
        async def collect_stream():
            nonlocal content
            user_id = kwargs.get('user_id', 'default')
            async for chunk in self.service.chat_stream(user_id, conversation_id, message):
                if chunk['type'] == 'text':
                    content += chunk['content']
        
        # è¿è¡Œå¼‚æ­¥å‡½æ•°
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(collect_stream())
        
        return {
            'content': content,
            'conversation_id': conversation_id,
            'model': self.model
        }
